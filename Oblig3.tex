\documentclass[9pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[norsk]{babel}
\usepackage{listings}
\DeclareUnicodeCharacter{00A0}{ }
\setcounter{section}{10}

\title{IMT2282 - Operativsystemer \\
	Oblig 2}
\author{Stian Hoel Bergseth \\
	130378}

\date{\today}


\begin{document}
\maketitle

\section{Chapter 11}
\setcounter{subsection}{5}
\subsection{Theory Questions}
\subsubsection{Hva er forskjellen på memory mapped og isolated I/O? Angi fordeler og ulemper med disse to prinsippene.}

Memory mapped IO er når IO enheter ( disker osv ) deler samme adresse bus som RAM. Dette gjør at CPUen kan bruke de samme instruksjonene for å snakke til RAM som til IO enheter, noe som senker kompleksiteten ved bruk av IO. Isolated IO er da det motsatte, hvor IO enheter har en egen adresse bus og krever ett eget sett med instruksjoner når CPUen ønsker å sende data til IO enheter. Ulempen med Memory mapped IO er at alle enheter som er koblet på det samme bus interfacet må følge samme klokkefrekvens, dette gjør at IO enheter må holde følge med CPU og RAM, noe som i praksis ikke er gjennomførbart. En av fordelen med isolated IO er da at CPU og RAM kan øke frekvensen på adresse busen utover det IO enheter klarer. Dette lar RAM og CPU "snakke" sammen i et større tempo, noe som igjen gir høyere ytelse. 
I dag har vi derfor endt opp med ( på x86 arkitekturen ) flere forskjellige bus varianter for forskjellig bruk, SATA til disker/optiske enheter, PCI express til expansjonskort ( med forskjellige størrelse for forskjellige mengder data ) og av det aller nyeste har vi fått M.2 disker som bruker PCI express interfacet.  \url{http://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=Bus_%28computing%29&id=651785312}


%I/O enheter, som f.eks disker, har egne registere for å ta imot og sende fra seg data. Hvis man skal snakke direkte til disse, isolated I/O , krever det at man har egne instruksjoner for å sende/hente data fra disse registrene. Hvis man heller bruker memory mapped I/O så kan man bruke de samme instruksjonene for å snakke med hurtigminnet og I/O enhetene. Dette ville krevd egne funksjoner for å komunisere med I/O enheter og ville skapt ekstra overhead sammenlignet med å bare kunne aksessere enhetene som variabler i hurtigminnet. En annen fordel er at man unngår behovet for egne sikkerhetsmekanismer for I/O enheter. Med memory mapped I/O så holder det at operativsystemet ikke tilegner prosesser minneadressene som er reservert til I/O. En av ulempene ved memory mapped I/O er at både hurtigminne og I/O enhetene må kunne få med seg alle forespørrsler CPUen gjør på adresse bus'en. Her har vi et problem ettersom hurtigminnet er raskt, mens I/O enheter er vesentlig treigere. Dette har man kommet rundt ved å ha en egen dedikert bus mellom CPU og RAM, mens I/O enhetene kan enten lytte på denne bus'en( men da vil ikke I/O enhetene klare å henge med ) eller så kan memory controlleren ha et predefinert sett med adresser som den flytter ut på en I/O bus hvis CPUen ønsker å snakke til en I/O enhet.

%Isolated I/O

\subsubsection{På en harddisk, hvor mange bytes finnes som regel i en sektor? Hva er en sylinder? Hva er typisk gjennomsnittlig aksesstid for en disk i dag? Hva er overføringsraten (ca, i MB/s) mellom diskplate og buffer?}

Som regel er det 512 bytes per sektor, men med "Advanced Format" er det på nyere disker vanlig med 4096 bytes per sektor. \url{http://en.wikipedia.org/w/index.php?title=Disk_sector&oldid=630789565}
En sylinder er det vertikale settet med sektorer på tvers av platene inne i en HDD.
I følge OS kompendiumet har en gjennomsnittlig disk i dag 4.2 ms aksesstid og en overføringsrate på ca 

512 bytes per sektor, 1 sektor tar 1,4 $\mu$s. Det er ca 714 286 sektorer per sekund. Som gir oss $714 286 * 512$ bytes som igjen er 365714432 bytes eller 348MB som human-readable-bytes.sh skriptet sier. Dette gir en overføringshastighet på 348 MB/s mellom diskplate og buffer.

\subsubsection{Hva oppnår vi med å koble diskene som RAID disker? Hvordan er diskene organisert på RAID-level 1. Forklar hvordan diskene er organisert på RAID-level 5.}

Ved å koble disker sammen i RAID kan vi få flere fysiske disker til å fremstå som en logisk enhet for datamaskinen. Ved å gjøre dette kan vi få økt ytelse, økt redundans av data eller begge deler. Dette oppnår vi ved å enten stripe data mellom disker, vi deler opp en I/O operasjon over flere disker og får økt ytelse ettersom vi utnytter paralleliteten mellom diskene. Økt redundans får vi ved speiling eller paritetsfunksjonalitet. Speiling vil si at vi skriver den samme dataen til alle diskene som er satt opp for speiling(Raid 1). For eksempel ved et 2 disk Raid 1 oppsett vil både disk 1 og disk 2 lagre all data. Paritetsfunksjonaliten fungerer ved at vi striper dataen over $N - 1$ og bruker den n'te disken til å lagre paritetsinformasjonen. I praksis har man endt opp med at diskene roterer på hvilken som skal være paritetsdisken(Raid 5). For eksmpel ved et 3 disk Raid5 oppsett vil det første være disk 1 og 2 som tar imot dataen, mens disk 3 lagrer paritetsinformasjonen. Neste operasjon vil skrive dataen til disk 2 og 3 mens disk 1 lagrer paritetsinformasjonen. Og slik fortsetter det.  

\subsubsection{Hvilke fire kriterier definerer et presist interrupt?}

I kompendiumet blir disse fire kriteriene gitt: \\ 
\begin{verbatim}
1. PC lagres på et kjent sted
2. Alle instruksjoner før PC er ferdig 
3. Ingen instruksjoner etter PC er kjørt 
4. Kjent tilstand for PC-instruksjonen
\end{verbatim}

PC er forkotelsen til program counter, som er informasjon om hvor langt prossesoren har kommet i ekskiveringsløpet av en process. For å få et presist interrupt må denne lagres på et kjent sted, slik at man kan finne den igjen, alle instruksjonene opp til program counteren må være ferdig kjørt, ingen instruksjoner som kommer etter program counteren kan ha kjørt. Den instruksjonen program counteren peker på kan være ferdig eller ikke vært påbegynt, men dette må da gjøres tydelig. 

\subsubsection{Forklar forskjellen mellom HDD og SSD når det gjelder lesing, skriving/overskriving og sletting av filer. Hva er poenget med TRIM kommandoen?}

Lesing:
Ettersom HDD har en mekanisk arm som må flyttes til det stedet på platen hvor den skal lese av data er det en relativt høy latency involvert med å finne dataen som skal leses. I en SSD finnes det ingen slik mekanisk løsning, alt foregår elektronisk og det er dermed mulig å oppnå raskere respons tid. I tilegg til raskere responstid er det mulig å utnytte parallelitet mellom flere NAND brikker i samme disk og dermed få høy overføringshastighet også ( 100MB/s~ for HDD og opp mot 1000MB/s~ for M2. SSD).
Skriving:
Her har også HDD samme problemet som ved lesning, det er en relativt høy latency for å finne riktig sted å skrive, men når den først kommer dit og kan skrive sekvensielt så har den ca samme ytelse som ved lesing. Derimot ved "random-write" så stuper ytelsen ettersom store deler av tiden går med på å flytte lesearmen. SSDer derimot har ikke samme problemet og kan også her utnytte parallelitet til skriving. Det er heller ingen mekanisk latency som gjør at "random-write" lider like mye. Det som derimot skjer er at SSDen mister fordelen med parallelitet ettersom disk controlleren ikke sprer mindre writes ( 4KB ) utover flere NAND ICer. 
Overskriving:
På en SSD er det en blokk som er den minste enheten man kan slette, som består av flere pages ( pages er den minste enheten man kan skrive til/lese fra på en SSD ). Etter at en page er skrevet til så må den slettes igjen før den kan "overskrives" og hver sletting tærer på livstiden til en SSD. Dette vil si at vi ønsker minst mulig sletting/overskrivninger på en SSD. En av måtene dettes løses på er at SSDen ikke skriver over, men hvis det er mulig skriver til en ny page istedet for den som skulle overskrives. Kun hvis det ikke er mulig å skrive til en ny page vil SSDen skrive over den gamle.
En HDD har ikke de samme problemene og skriver bare over den sektoren OSet har bedt den om å skrive over.
Sletting:
Ingen av disk variantene sletter noe, bortsett fra SSDen når det er absolutt nødvendig.

TRIM:
Poenget med TRIM kommandoen er å slippe ytelsestapet som oppstår ved overskriving av en page. Ettersom disken ikke sletter filer når du faktisk ber om det så vil overskriving kunne forekomme relativt ofte. Det TRIM kommandoen gjør er å "rydde opp" på disken i bakgrunnen. Når OSet markerer en page som slettet vil TRIM kommandoen lagre blokken som pagen var en del av i en cache, slette hele blokken og skrive tilbake det som ikke skulle slettes i blokken. Dette gjør at det "alltid" er tomme pages tilgjengelig for skriving når en ny fil kommer inn og man klarer å opprettholde ytelsen ved skriving til disk.

\subsubsection{Hva betyr det at et operativsystem er tilpasset SSD disker (slik som f.eks. Windows 7 er).}

At et OS er tilpasset SSDer vil si at det støtter TRIM kommandoen og at OSet klarer å skille på HDD vs SSD slike at det ikke prøver å defragmentere SSDen. I tilegg burde filsystemet sin blokkstørrelse sammensvare med SSDen sin page størrelse og disse burde være likestilte slik at en IO operasjon som kunne blitt behandlet av en page blir spred ut over flere pages.
\subsection{Lab exercises}
\subsubsection{Skriv en PowerShell-kommandolinje som skriver ut alle prosesser som har working set større enn 10MB. Det skal skrives ut prosessnavn, prosess-ID og working set-størrelse, sortert på working set-størrelse.}
\begin{lstlisting}[breaklines]
Get-Process | Where-Object {$_.WorkingSet -gt 10MB } | Sort-Object workingSet -Descending | Format-Table -Property ProcessName,Id,WorkingSet -AutoSize
\end{lstlisting}
\subsubsection{Lag et script myprocinfo.ps1 som gir brukeren følgende meny med tilhørende funksjonalitet: \\
1 - Hvem er jeg og hva er navnet på dette scriptet? \\
2 - Hvor lenge er det siden siste boot? \\
3 - Hvor mange prosesser og tråder finnes? \\
4 - Hvor mange context switch'er fant sted siste sekund? \\
5 - Hvor stor andel av CPU-tiden ble benyttet i kernelmode og i usermode siste sekund? \\
6 - Hvor mange interrupts fant sted siste sekund? \\
9 - Avslutt dette scriptet \\
Velg en funksjon:
}

Løsning ligger her: 
\section{Chapter 12}
\setcounter{subsection}{2}
\subsection{Theory Questions}
\subsubsection{Det kreves at fire ulike betingelser alle må være oppfylt for at deadlock skal inntre. Beskriv disse kort.}



\subsubsection{Hva vil det si at en tilstand er “unsafe” i forbindelse med deadlock}

\subsubsection{Forklar kort hva en ressursgraf er og hvordan den kan benyttes til å avsløre om vi har en deadlock situasjon}

\subsubsection{Tanenbaum oppgave 6.2 Students working at individual PCs in a computer laboratory send their files to be printed by a server which spools the files on its hard disk. Under what conditions may a deadlock occur if the disk space for the print spool is limited? How may deadlock be avoided?}

\subsubsection{Tanenbaum oppgave 6.25 A computer has six tape drives, with n processes competing for them. Each process may need two drives. For which values of n is the system deadlock free?}

\subsubsection{A system has four processes and five allocatable resources. The current allocation and maximum needs are as follows: }
\begin{verbatim}
       Allocated  Maximum    Available
ProcA  1 0 2 1 1  1 1 2 1 3  0 0 x 1 1
ProcB  2 0 1 1 0  2 2 2 1 0
ProcC  1 1 0 1 0  2 1 3 1 0
ProcD  1 1 1 1 0  1 1 2 2 1
\end{verbatim}
What is the smallest value of x for which this is a safe state?


\
\end{document}
